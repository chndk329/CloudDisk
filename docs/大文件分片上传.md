# 大文件分片上传（==重难点==）

对于大文件而言，不能一次性把文件中的所有内容进行上传，所以需要分成多个片段进行，并且因为如果发送失败，需要重发整个大文件，而采用分片上传，有分片丢失了只需重传丢失的分片。

与**阿里云的OSS**的分片上传思路是一致的。（阿里云：单个文件大于5G才算是大文件）

https://help.aliyun.com/zh/oss/user-guide/multipart-upload-12?spm=a2c4g.11186623.0.0.2cf45e6fna2ogs

>   OSS：Object Storage Service

方向：客户端上传文件到服务器

客户端：postman模拟

服务端：Workflow

三个阶段：初始化阶段、上传阶段、收尾阶段



## 引用场景

-   **大文件加速上传**

    当**文件大小超过5G**时，使用分片上传可以实现**并行上传**多个part以加快上传速度

-   **网络环境较差**

    网络环境较差时，建议使用分片上传，当出现上传失败时，仅需要重传失败的part

-   **文件大小不确定**

    可以在需要上传的文件大小还不确定的情况下开始分片上传，这种场景在**视频监控**等行业应用中比较常见



## 补充

改进：（阿里云）终止上传任务，可调用[AbortMultipartUpload](https://help.aliyun.com/zh/oss/developer-reference/abortmultipartupload#reference-txp-bvx-wdb)接口，成功上传的Part会一并删除。



## 阶段一：初始化

### 客户端

```url
http://192.168.10.128:8888/file/mupload/init?username=Tvux
```

>   改进：补充携带token
>
>   ```url
>   http://192.168.10.128:8888/file/mupload/init?username=Tvux&token=xxx
>   ```



客户端发送POST请求给服务器，请求体是一个JSON

```json
# application/json
{
    "filename": "bigfile",
    "filesize": 1972935873,
    "filehash": "6c68f4d5676fa9b5331d493357627f86b5200081"
}
```

>   所以index.html页面的前端代码中包含计算sha1的方法，由客户端计算sha1然后发送给服务器



filehash可以使用md5码

```shell
md5sum bigfile
a54d782453b2527e7d537dfa0d3513f5
```

如果md5码发生冲突？

可以使用sha1

```shell
sha1sum bigfile
6c68f4d5676fa9b5331d493357627f86b5200081
```

类似的还有sha3、sha256、sha512等

>   MD5（Message Digest Algorithm 5），相对更快
>
>   SHA-1（Secure Hash Algorithm 1），相对更安全
>
>   Simhash？适用于计算文本相似度



### 服务器

服务器收到客户端发送的post请求后

1、解析请求

username：Tvux

>   token：xxx

文件名filename、文件大小filesize、文件hash值filehash

2、对于**每一个文件**的上传要生成唯一的ID，称为uploadID

用户名+时间信息（年月日时分秒）

3、生成分片信息

chunksize：1024*1024\*100 = 100M

chunkcnt：filesize / chunksize + (filesize % chunksize > 0 ? 1 : 0)



```
1972935873 / 1024*1024*100 = 18
+ 1972935873 % 1024*1024*100 = 1
= 18 + 1 = 19
```



4、生成响应信息，封装成JSON发回给客户端

5、服务器存储uploadID对应的信息，存入Redis

```redis
HSET uploadID
filename ...
filesize ...
filehash ...
chunksize ...
chunkcnt ...
```



## 阶段二：上传分片

客户端可以考虑多线程

### 客户端

客户端收到了分片大小chunksize和分片数量chunkcnt以及上传文件的唯一标识uploadID

然后发送一个post请求给服务器，包括uploadID和分片索引chunkidx（表示这次发的是这个文件的第几个分片），请求体是分片内容

```url
http://192.168.10.128:8888/file/mupload/uppart?uploadID=Tvux20231003204911&chunkidx=0
```

```
// 请求体
text/plain

模拟分片的数据
...
...
```



### 服务器

服务器收到客户端发来的post请求

1、解析请求

​	得到的是uploadID、chunkidx以及对应的分片内容

2、存储分片的内容

​	生成一个临时文件夹uploadID

​	将分片内容写入临时文件夹 0 1 2 3…

3、在Redis中写入分片的记录

​	不需要合并分片就知道文件的所有分片是否上传完

```redis
HSET uploadID
0 1
1 1
2 1
3 1
```

4、告知客户端，分片信息接收成功





## 阶段三：收尾

### 客户端

```url
http://192.168.10.128:8888/file/mupload/complete?uploadID=Tvux20231003204911
```

发送get请求给服务器，文件已经上传完毕



### 服务器

服务区接收客户端发送过来的get请求

1、解析请求

获取到uploadID

2、访问Redis，检查分片信息是否全部接收

```redis
HGETALL uploadID
filename
filesize
fielhash
chunksize
chunkcnt 4
chunkidx_0 1
chunkidx_1 1
chunkidx_2 1
chunkidx_3 1
```

3、进行校验

-   检查分片记录是否完全
    -   分片记录完整的情况下：
        -   合并文件 - 遍历临时目录uploadID - 读取目录下所有文件 - 按文件的顺序依次读取并写入到filename的文件中
        -   校验hash值 - sha1 - 使用openssl计算文件的sha1，然后与数据库中存储的sha1进行比对，如果一直则上传成功
        -   删除临时文件夹 uploadID
    -   分片记录不完整：
        -   给客户端发送响应信息，可以补充设置响应报文的状态等
        -   然后使用JSON告知客户端缺少了哪些分片，客户端进行重传（uppart）

![image-20231004195701506](%E5%A4%A7%E6%96%87%E4%BB%B6%E5%88%86%E7%89%87%E4%B8%8A%E4%BC%A0.assets/image-20231004195701506.png)

4、生成响应信息，发送给客户端



## 代码实现

```cpp
#include <workflow/WFFacilities.h> // for WaitGroup - WFFacilities这个类里面定义的内部类, include "WFTaskFactory.h" - for WFHttpTask
#include <workflow/WFHttpServer.h> // for WFHttpServer
/* #include <workflow/json_parser.h> // for json，Workflow自带的JSON解析，C语言实现，感觉不是很好用 */
// 也可以使用nlohmann::json来解析JSON
#include <nlohmann/json.hpp>
/* #include <nlohmann/json.hpp> */
#include <iostream>
#include <functional> // for bind
#include <string> // for string
#include <ctime> // for localtime
#include <vector> // for vector
#include <sys/stat.h> // for mkdir
#include <fstream> // for ofstream
#include <set> // for set
using namespace std;


class MuploadServer {
public:
    MuploadServer(unsigned short port_)
        : port(port_)
          // 注意：这里process是成员函数，第一个参数是this指针
          // 要传入的话，第一个方法可以使用bind
          /* , http_server(std::bind(&MuploadServer::process, this, std::placeholders::_1)) */
          // 第二个方法是使用lambda表达式
          , http_server([this](WFHttpTask* server_task){ this->process(server_task); })
          , wait_group(1)  
    {}

    void start();
    void stop();

private:
    void process(WFHttpTask* server_task);
    void init(WFHttpTask* server_task, const string& username);
    void uppart(WFHttpTask* server_task, const string& uploadID, const string& chunkidx);
    void complete(WFHttpTask* server_task, const string& uploadID);

    string produceUploadID(const string& username);

private:
    unsigned short port;
    WFHttpServer http_server;
    WFFacilities::WaitGroup wait_group;
};


void MuploadServer::start() {
    int ret = http_server.start(port);
    if (ret == 0) {
        cout << "http_server start success!" << endl;
        wait_group.wait();
        stop();
    }
    else {
        cout << "http_server start failed!" << endl;
    }
}

void MuploadServer::stop() {
    http_server.stop();
}

void MuploadServer::process(WFHttpTask* server_task) {
    // 只要执行process函数，一定接收到了对端的请求数据
    cout << endl << endl << "MuploadServer::process is running" << endl;

    // 0. 对请求的状态进行检测
    int state = server_task->get_state();
    int error = server_task->get_error();
    
    cout << "state = " << state << endl;
    switch(state) {
    case WFT_STATE_SYS_ERROR:
        cout << "system error: " << strerror(error) << endl;
    case WFT_STATE_DNS_ERROR:
        cout << "dns error: " << gai_strerror(error) << endl;
    case WFT_STATE_TOREPLY:
        break;
    }

    if (state != WFT_STATE_TOREPLY) {
        cout << "ERROR!" << endl;
        return;
    }

    cout << "recv resquest success!" << endl;

    // 1. 解析请求
    protocol::HttpRequest* http_req = server_task->get_req();
    string uri = http_req->get_request_uri();
    string method = http_req->get_method();

    // uri中一定是有查询词的
    string api_path = uri.substr(0, uri.find("?"));

    const string api_init = "/file/mupload/init";
    const string api_uppart = "/file/mupload/uppart";
    const string api_complete = "/file/mupload/complete";

    if (method == "POST" && api_path == api_init) {
        // 解析username
        string username = uri.substr(uri.find("=") + 1);

        init(server_task, username);
    }
    else if (method == "POST" && api_path == api_uppart) {
        // 解析uploadID和chunkidx
        string uploadIDKV = uri.substr(0, uri.find("&"));
        string uploadID = uploadIDKV.substr(uploadIDKV.find("=") + 1);

        string chunkidxKV = uri.substr(uri.find("&"));
        string chunkidx = chunkidxKV.substr(chunkidxKV.find("=") + 1);

        uppart(server_task, uploadID, chunkidx);
    }
    else if (method == "GET" && api_path == api_complete) {
        // 解析uploadID
        string uploadID = uri.substr(uri.find("=") + 1);
        cout << uploadID << endl;

        complete(server_task, uploadID);
    }
}

string MuploadServer::produceUploadID(const string& username) {
    time_t now = time(0);
    // man localtime
    struct tm* ptm = localtime(&now);
    char buf[15] = { 0 };
    // 4 + 2 + 2 + 2 + 2 + 2
    // 年  月  日  时  分  秒
    // 一共14个字节，+1存储'\0'
    sprintf(buf, "%04d%02d%02d%02d%02d%02d",
            ptm->tm_year + 1900,
            ptm->tm_mon + 1,
            ptm->tm_mday,
            ptm->tm_hour,
            ptm->tm_min,
            ptm->tm_sec);
    return username + string(buf);
}

void MuploadServer::init(WFHttpTask* server_task, const string& username) {
    cout << endl << "init:" << endl;
    cout << "username = " << username << endl;

    // 1. 生成uploadID
    string uploadID = produceUploadID(username); 

    // 2. 获取请求报文的消息体
    protocol::HttpRequest* http_req = server_task->get_req();

    const void* body = nullptr;
    size_t size = 0;
    http_req->get_parsed_body(&body, &size);

    string req_body_str((const char*)body, size);
    using Json = nlohmann::json;
    Json req_body_json = Json::parse(req_body_str);

    string filename = req_body_json["filename"];
    size_t filesize = req_body_json["filesize"];
    string filehash = req_body_json["filehash"];

    cout << "filename = " << filename << endl;
    cout << "filesize = " << filesize << endl;
    cout << "filehash = " << filehash << endl;

    // 3. 生成分片信息
    // 分片大小：100M 可以设计成可扩展的
    // 比如：如果文件大小是1G以上，可以一个分片大小是100M
    // 一个文件大小是1M，可以一个分片大小是100K
    const size_t chunksize = 1024 * 1024 * 100;
    size_t chunkcnt = filesize / chunksize + (filesize % chunksize > 0 ? 1 : 0);
    cout << "chunkcnt = " << chunkcnt << endl;

    // 4. 将uploadID对应的信息存入Redis
    const string redis_url = "redis://127.0.0.1:6379";
    // 不需要回调函数，因为只需要写入数据（在redis_task的基本工作阶段就已经完成）
    auto redis_task = WFTaskFactory::create_redis_task(redis_url, 1, nullptr); 
    string redis_cmd = "HSET";
    vector<string> redis_params {
        uploadID,
        "filename", filename,
        "filesize", to_string(filesize),
        "filehash", filehash,
        "chunksize", to_string(chunksize),
        "chunkcnt", to_string(chunkcnt)
    };
    redis_task->get_req()->set_request(redis_cmd, redis_params);
    series_of(server_task)->push_back(redis_task);

    // 5. 生成响应信息，打包成JSON，发送给客户端
    Json resp_body = {
        "uploadID", uploadID,
        "chunksize", chunksize,
        "chunkcnt", chunkcnt
    };
    string resp_body_str = resp_body.dump();
    protocol::HttpResponse* http_resp = server_task->get_resp();
    http_resp->append_output_body(resp_body_str.c_str(), resp_body_str.size());
}

void MuploadServer::uppart(WFHttpTask* server_task, const string& uploadID, const string& chunkidx) {
    cout << endl << "uppart:" << endl;
    cout << "uploadID = " << uploadID << endl;
    cout << "chunkidx = " << chunkidx << endl;

    // 1. 获取请求消息体 - 分片内容
    const void* body = nullptr;
    size_t size = 0;
    server_task->get_req()->get_parsed_body(&body, &size);
    string req_body_str((const char*)body, size); 

    // 2. 将uploadID作为临时文件夹
    mkdir(uploadID.c_str(), 0755);

    string filepath = uploadID + "/" + chunkidx;
    ofstream ofs(filepath);
    if (!ofs.good()) {
        cerr << "open " << filepath << " failed!" << endl;
        ofs.close();
        server_task->get_resp()->append_output_body("uppart chunkidx " + chunkidx + " failed!");
        return;
    }
    ofs << req_body_str;
    ofs.close();

    // 3. 分片写入成功的记录写入Redis中
    const string redis_url = "redis://127.0.0.1:6379";
    auto redis_task = WFTaskFactory::create_redis_task(redis_url, 1, nullptr); 
    string redis_cmd = "HSET";
    vector<string> redis_params {
        uploadID,
            "chunkidx_" + chunkidx, "1"
    };
    redis_task->get_req()->set_request(redis_cmd, redis_params);
    series_of(server_task)->push_back(redis_task);

    // 4. 生成响应信息给客户端
    server_task->get_resp()->append_output_body("recv chunkidx " + chunkidx + " success!");
}

void MuploadServer::complete(WFHttpTask* server_task, const string& uploadID) {
    cout << endl << "complete:" << endl;
    cout << "uploadID = " << uploadID << endl;

    // 1. 访问Redis，检查分片信息是否全部接收
    const string redis_url = "redis://127.0.0.1:6379";
    auto redis_task = WFTaskFactory::create_redis_task(redis_url, 1, 
    [server_task](WFRedisTask* redis_task){
        // 获取响应信息
        protocol::RedisValue res;
        protocol::RedisResponse* redis_resp = redis_task->get_resp();
        redis_resp->get_result(res);
        if (res.is_array()) {
            int chunkcnt;
            int cur_chunkcnt = 0;
            set<int> chunks;

            for (size_t i = 0; i < res.arr_size(); i += 2) {
                string key = res.arr_at(i).string_value();
                string val = res.arr_at(i + 1).string_value();
                if (key == "chunkcnt") {
                    chunkcnt = stoi(val);
                    for (int i = 0; i < chunkcnt; ++i) {
                        chunks.insert(i);
                    }
                }
                // 这里可以用一个set来记录已经存在的分片记录
                // 然后告诉用户重传哪些缺少的分片
                if (key.substr(0, 9) == "chunkidx_") {
                    ++cur_chunkcnt;
                    string cur_chunkidx = key.substr(9);
                    chunks.erase(stoi(cur_chunkidx));
                }
            }

            if (cur_chunkcnt < chunkcnt) {
                using Json = nlohmann::json;
                Json resp_body_json = {
                    "msg", "Fragment Missing",
                    "chunks", chunks
                };
                server_task->get_resp()->append_output_body(resp_body_json.dump());
            }
            else {
                // 分片数量相等
                // 
                // 合并文件 - 遍历临时目录uploadID - 读取目录下所有文件 - 按文件的顺序依次读取并写入到filename的文件中
                // 校验hash值 - sha1 - openssl
                // 删除临时文件夹 uploadID
                // 
                // 生成响应信息给客户端
                server_task->get_resp()->append_output_body("upload success!");
            }
        }
        else {
            // Redis的返回值不是一个array，也是失败
            server_task->get_resp()->append_output_body("upload failed!");
        }
    }); 
    string redis_cmd = "HGETALL";
    vector<string> redis_params { uploadID };
    redis_task->get_req()->set_request(redis_cmd, redis_params);
    series_of(server_task)->push_back(redis_task);
}

void test() {
    MuploadServer m_upload_server(8888);
    m_upload_server.start();
}

int main(void) {
    test();
    return 0;
}
```



## 常见问题

### 如何删除碎片（分片）？

您可以通过以下两种方式删除碎片：

-   自动删除

    所有分片上传完成并合并为文件之后会自动删除分片所在的文件夹，从而删除所有分片

-   手动删除

    调用AbortMultipartUpload接口取消MultipartUpload事件并删除对应的碎片。



### 分片上传过程中断后，重新上传时是否会覆盖已上传Part？

分片上传过程中断后，如果使用**同一个Upload ID**重新上传所有Part，则**会覆盖**之前上传的同名Part；

如果使用**新的Upload ID**重新上传所有Part，**旧的Upload ID**中的分片会作为碎片**继续保留**。



### 分片上传时Upload ID是什么含义？

Upload ID用于**唯一标识分片上传事件**。对于同一个Upload ID，分片号（PartNumber）用于标识该分片在整个文件内的相对位置。



### 分片上传时Upload ID有效期多久？

Upload ID**在分片上传过程中一直有效**，如果上传**终止**或上传**完成**，Upload ID将失效。如果需要再次分片上传，您需要重新初始化生成一个新的Upload ID。



### OSS是否支持自动合并分片?

OSS不支持自动合并分片，您需要通过调用[CompleteMultipartUpload](https://help.aliyun.com/zh/oss/developer-reference/completemultipartupload#reference-lq1-dtx-wdb)手动合并分片。